<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python Unit Testing]]></title>
    <url>%2F2019%2F10%2F30%2FPython-Unit-Testing%2F</url>
    <content type="text"><![CDATA[Unit TestingWhat is unit testing? Unit testing simply verifies that individual units of code (mostly functions) work as expected. Usually you write the test cases yourself, but some can be automatically generated. The unit testing should be done as often as possible. The most obvious benefit is knowing down the road that when a change is made, no other individual units of code were affected by it if they all pass the tests. Example of testing Student classHere I’m going to make a very simple example to show how it works. First, build the Student class: 123456789101112131415161718class Student(): def __init__(self, name, score): self.name = name self.score = score self.grade = None def to_grade(self): if self.score &gt;= 60: self.grade = 'Pass' else: self.grade = 'Fail' def get_grade(self): if self.grade: return self.grade else: self.to_grade() return self.grade Then, build the unit testing script: 12345678910111213141516171819import unittestfrom Student import Studentclass TestStudent(unittest.TestCase): def test_above_60(self): s1 = Student('bart', 60) self.assertEqual(s1.get_grade(), 'Pass') def test_below_60(self): s1 = Student('bart', 50) self.assertEqual(s1.get_grade(), 'Fail') def test_invalid(self): passif __name__ == "__main__": unittest.main() ExecutionExecute the script to make testing: 1python test_student.py to make the outut more verbose, add the -v into the command. 1python test_student.py -v Reference blog of liaoxuefeng: https://www.liaoxuefeng.com/wiki/1016959663602400/1017604210683936 doc of Python 3.8: https://docs.python.org/3/library/unittest.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python decorator pattern]]></title>
    <url>%2F2019%2F10%2F24%2FPython-decorator-pattern%2F</url>
    <content type="text"><![CDATA[DecoratorsWhat is decorators? It accepts the functions and add the decorator-like function into the original functions to achieve certain functions. Examples: Apply the function of measuring execution time on each function. 12345678910111213141516171819202122# -*- coding: utf-8 -*-import time# --exe_timedef exe_time(func): def new_func(*args, **args2): t0 = time.time() print "@%s, &#123;%s&#125; start" % (time.strftime("%X", time.localtime()), func.__name__) back = func(*args, **args2) print "@%s, &#123;%s&#125; end" % (time.strftime("%X", time.localtime()), func.__name__) print "@%.3fs taken for &#123;%s&#125;" % (time.time() - t0, func.__name__) return back return new_func# --end of exe_time@exe_timedef foo(): for i in xrange(10000000): passif __name__ == "__main__": foo() See more details in the blog of liaoxuefeng. Reference liaoxuefeng: Decorators https://www.liaoxuefeng.com/wiki/1016959663602400/1017451662295584 Python: 使用装饰器“@”取得函数执行时间 https://oldj.net/blog/2010/05/22/decorator-get-execution-time]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python map filter and reduce]]></title>
    <url>%2F2019%2F09%2F19%2FPython-map-filter-and-reduce%2F</url>
    <content type="text"><![CDATA[Map, Filter and ReduceMapMap applies a function to all the items in an input_list. Given an example: 12items = [1, 2, 3, 4, 5]squared = list(map(lambda x: x**2, items)) The use blueprint is 1map(function_to_apply, list_of_inputs) Note that the function could be list of functions. FilterAs the name suggests, filter returns the list of elements for which a function returns true. Given an example: 12345number_list = range(-5, 5)less_than_zero = list(filter(lambda x: x &lt; 0, number_list))print(less_than_zero)# Output: [-5, -4, -3, -2, -1] ReduceReduce is a really useful function for performing some computation on a list and returning the result. It applies a rolling computation to sequential pairs of values in a list. For example, if you wanted to compute the product of a list of integers. So the normal way you might go about doing this task in python is using a basic for loop: 123456product = 1list = [1, 2, 3, 4]for num in list: product = product * num# product = 24 Now let’s try it with reduce: 123456from functools import reduceproduct = reduce((lambda x, y: x * y), [1, 2, 3, 4])# Output: 24# map and filter are both in built-in module. # The REDUCE need to be imported. Reference Map, Filter and Reduce https://book.pythontips.com/en/latest/map_filter.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python sys.stdin/stdout]]></title>
    <url>%2F2019%2F09%2F19%2FPython-sys-stdin-stdout%2F</url>
    <content type="text"><![CDATA[stdin is used for all interactive input, including calls to input().stdout is used for the output of print() and expression statements and for the prompts of input() For sys.stdin, you can use sys.stdin.readline() sys.stdin.readlines() For more details, read the reference articles. Reference Chapter 20 - The sys Module https://python101.pythonlibrary.org/chapter20_sys.html (this is a good website for python learner) Python Concepts/Console Input https://en.wikiversity.org/wiki/Python_Concepts/Console_Input]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python os.path module]]></title>
    <url>%2F2019%2F08%2F06%2FPython-os-path-module%2F</url>
    <content type="text"><![CDATA[Common Usage of os.path moduleThis article records some very common usages of os.path module in Python. Since there are few examples in the docs of os.path module, I added examples for all part in this article. os.path.expanduser()Expand ~ and ~user constructions. If user or $HOME is unknown, do nothing. 1234567path = "~/file.txt"full_path = os.path.expanduser(path)# return: '/Users/shuo/file.txt'os.environ["HOME"] = "/home / GeeksForGeeks"full_path = os.path.expanduser(path)# return: '/home / GeeksForGeeks/file.txt' os.path.join()Join one or more path components intelligently. 1234&gt;&gt;&gt; os.path.join('a','b','c')'a/b/c'&gt;&gt;&gt; os.path.join('a','b','c','')'a/b/c/' os.path.split()Split the pathname path into a pair, (head, tail) where tail is the last pathname component and head is everything leading up to that. The tail part will never contain a slash; if path ends in a slash, tail will be empty. If there is no slash in path, head will be empty. If path is empty, both head and tail are empty. 1234567&gt;&gt;&gt; test_s="/home/sa2y18/mydocuments"&gt;&gt;&gt; os.path.split(test_s)('/home/sa2y18', 'mydocuments')&gt;&gt;&gt; test_s=test_s+'/'&gt;&gt;&gt; os.path.split(test_s)('/home/sa2y18/mydocuments', '') Reference https://docs.python.org/2/library/os.path.html my gist]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python with statement in IO]]></title>
    <url>%2F2019%2F08%2F06%2FPython-with-statement-in-IO%2F</url>
    <content type="text"><![CDATA[In Python you need to give access to a file by opening it. open() in usual caseIf you don’t use with statement, you should write like this: 1234567file = open("welcome.txt")data = file.read()print datafile.close() # It's important to close the file when you're done with it file.close() is important, especially in the writing mode. If you don’t close(), the writing action can’t really take effect. use with in Python IO12345678910with open("welcome.txt") as file: # Use file to refer to the file object data = file.read() do something with data # open in write mode with open('output.txt', 'w') as file: # Use file to refer to the file object file.write('Hi there!') Notice, that we didn’t have to write file.close() in the case of using with open() as xx. That will automatically be called. Reference With statement in Python : https://www.pythonforbeginners.com/files/with-statement-in-python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch torch.no_grad()]]></title>
    <url>%2F2019%2F08%2F06%2FPytorch-torch-no-grad%2F</url>
    <content type="text"><![CDATA[What is torch.no_grad() for?When using Pytorch, if we want to do testing after the training, the model.eval() switches the mode into eval mode. The batchnorm and dropout layers would not work on that case and make sure the values pass through the network. When I read more code, I found that the torch.no_grad() is also widely used in Pytorch project. What is this for? According to the discussion on https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615. The model.eval() and with torch.no_grad() two functions have different goals: model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script). — answered by @albanD Example of torch.no_grad() SPATIAL TRANSFORMER NETWORKS TUTORIAL:https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html12345678910111213141516171819def test(): with torch.no_grad(): model.eval() test_loss = 0 correct = 0 for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) # sum up batch loss test_loss += F.nll_loss(output, target, size_average=False).item() # get the index of the max log-probability pred = output.max(1, keepdim=True)[1] correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) print('\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n' .format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) I also reproduce this code on my github repo: https://github.com/ShuoGH/deepLearningAl Using torch.no_grad() would accelerate the computation of neural network. Reference Pytorch Forum: ‘model.eval()’ vs ‘with torch.no_grad()’: https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Server Miniconda Installation]]></title>
    <url>%2F2019%2F08%2F06%2FLinux-Server-Miniconda-Installation%2F</url>
    <content type="text"><![CDATA[Install the Miniconda environment on Remote ServerAnaconda installation doesn’t need to ask for the admin permission. So it’s a good choice used on server. I would show how to install on the server in the following. Download the Miniconda package12345# use `curl` to download the package from miniconda. In own computer of MacOS.curl -O "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"# use `wget` to download the package, in the serverwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda_package Install on the Server12345# give the execute permission of the filechmod +x /path/to/yourscript.sh# run. `./` is important, since it points to the current path./yourscript.sh Activate the Environment1234source Miniconda/bin/activate # deactivate the environment, just type in the terminaldeactivate Then you have the environment for your project, you can just use pip install xx to install the modules you need. Reference Reddit: what advantages of using anaconda]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python argparse for Command Line]]></title>
    <url>%2F2019%2F07%2F23%2FPython-argparse-for-Command-Line%2F</url>
    <content type="text"><![CDATA[Intro of argparseThe argparse module makes it easy to write user-friendly command-line interfaces. The program defines what arguments it requires, and argparse will figure out how to parse those out of sys.argv(see the following part for the details of this). You can’t keep using Jupyter notebook all the time. The scripts files and a whole projects needs to be created for our task. The argparse is the communication tools which let developers to make changes to the script from the terminal and don’t need to go into the code and change the parameters. example 1234567891011import argparseparser = argparse.ArgumentParser(description='Process some integers.')parser.add_argument('integers', metavar='N', type=int, nargs='+', help='an integer for the accumulator')parser.add_argument('--sum', dest='accumulate', action='store_const', const=sum, default=max, help='sum the integers (default: find the max)')args = parser.parse_args()print(args.accumulate(args.integers)) This is a program that takes a list of integers and produce either the sum or the max. Assume the name of file is prog.py, and execute the file: 12345python prog.py 1 2 3 4# output: 4python prog.py 1 2 3 4 --sum# output: 10 See the details from docs of argparse. Elsesys.argvDuring using the argparse module, sys.argv is important since you may need it in the main()function. Code is sometimes like this: 12345678910import argparseimport sys def main(argv): parser = argparse.ArgumentParser() # parser.add_argument() # Do some argument parsingif __name__ == '__main__': main(sys.argv) sys.argv is the list of commandline arguments passed to the Python program. It represents all the items that come along via the command line input. For the content of argv, the first argument is always the script name, and it is also counted in the number of arguments. So even if you don’t pass any argument into your script, the sys.argv variable always contains at least one element and it’s the script name. Example Execute this python script, assume it is named test.py. 1234import sysprint "This is the name of the script: ", sys.argv[0]print "Number of arguments: ", len(sys.argv)print "The arguments are: " , str(sys.argv) 1python test.py The output should be: 123This is the name of the script: sysargv.pyNumber of arguments in: 1The arguments are: ['test.py'] Reference python docs: argparse How to use sys.argv in Python ](https://www.pythonforbeginners.com/system/python-sys-argv) https://appdividend.com/2019/01/22/python-sys-argv-tutorial-command-line-arguments-example/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Counting Files in Directory]]></title>
    <url>%2F2019%2F07%2F03%2FLinux-Counting-Files-in-Directory%2F</url>
    <content type="text"><![CDATA[Counting the files in a directory. When I was doing my summer project, I downloaded the datasets into the server and unzipped the zip file. Since it has a large amount of files in the dir, I want to count the number of files just through the terminal. First try1ls -1 | wc -l Use this command after getting into the dir, it can count the number of files in the current dir. Note: the first 1 is ONE, and the second l is the l for large. Result: it seems that I can’t perform well, since the speed is slow and need to spend a lot of time to get the result( I didn’t wait for that long to get the final result). Note: wc is great when I search this command. 12wc -l &lt; file.txtwc -w file2.txt The first line of code can count the number of lines in a text file. The second line of code can count the words in the text file. Improvement to get my resultSince I have the nohup.out, I can count the line number to know how many files I have uncompressed. The uncompressing process is a really long journey…for my project Reference Bash Prompt HOWTO: Counting Files in the Current Directory]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Delete Files Bash Command]]></title>
    <url>%2F2019%2F07%2F03%2FLinux-Delete-Files-Bash-Command%2F</url>
    <content type="text"><![CDATA[To delete files on Linux server, there are multi ways to achieve this. rm bash command1rm [options] ...file... I usually use rm -rf file folder_name to remove a non-empty filefolder. Options: -f, —force Ignore nonexistent files, never prompt -r, -R, —recursive Remove directories and their contents recursively. and some other options, see the reference 1 for the doc. rsyncrsync is an alternative method which can be used in deleting files. It is suitable for the folder which contains a large amount of files, in which case rm -rf can’t behave well. 12mkdir emptyrsync -a --delete empty/ your_folder/ Reference Bash man doc: rm Bash man doc: rsync StackExchange: Efficiently delete large directory containing thousands of files]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tar for unzipping]]></title>
    <url>%2F2019%2F07%2F02%2FLinux-tar-for-unzipping%2F</url>
    <content type="text"><![CDATA[1tar xvzf file.tar.gz x: This option tells tar to extract the files. v: The “v” stands for “verbose.” This option will list all of the files one by one in the archive. z: The z option is very important and tells the tar command to uncompress the file (gzip). f: This options tells tar that you are going to give it a file name to work with. Note:For compressing files, you can use1tar cvfz file.tar.gz dir/ The z tell that the files are compressed using gzip, and we usually name the zipped file .tar.gz. Reference How To Extract .tar.gz Files using Linux Command Line 每天一个linux命令（61）：tar命令]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux wget for downloading]]></title>
    <url>%2F2019%2F07%2F02%2FLinux-wget-for-downloading%2F</url>
    <content type="text"><![CDATA[wget for downloading files in Terminal. When I was doing my summer project, I should download the datasets into the server. To achieve this, I used the wget and records the infor of this command by this chance. Introduction of wgetGNU Wget is a free utility for non-interactive download of files from Web. It supports HTTP, HTTPS, and FTP protocols, as well as retrieval through HTTP proxies. Non-interactive means that it can work in the background. To invoke: 1wget [option]… [URL]… Some more about Using Download file in the background: 1wget -b [URL] Check the information of the downloading: 1tail -f wget-log Download file and change the name 1wget -O [name] [URL] Download multiple files 1wget -i filelist.txt The filelist.txt should have the urls of the targets files. To unzip the .tar.gz file, use the command tar. See the blog Linux tar for unzipping. Reference: GNU Wget 1.20 Manual 每天一个linux命令（61）：wget命令]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Can Python Interprete itself?]]></title>
    <url>%2F2019%2F07%2F02%2FCan-Python-Interprete-itself%2F</url>
    <content type="text"><![CDATA[The interpreter of Python can be written with Python, such as the most famous one PyPy. There are several advantages using PyPy, like the speed, memory usage, compatibility and stackless. In the tutorial of Allison Kaptur, the Python interpreter is a stack machine: it manipulates several stacks to perform its operations( as contrasted with a register machine, which writes to and reads from particular memory locations). Reference: Allison Kaptur A Python Interpreter Written in Python)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Interpreter]]></title>
    <url>%2F2019%2F07%2F02%2FPython-Interpreter%2F</url>
    <content type="text"><![CDATA[python解释器 编写python代码时，得到的是一个包含python代码的.py为拓展名的文本文件。要运行代码的时候，需要python解释器去执行.py文件。 事实上，存在有很多python解释器。 CPython从python官网下载并安装好python3.x之后，我们会直接获得一个官方版本的解释器CPython. 这个解释器是用C语言开发的，所以叫CPython。 CPython是使用最广的Python解释器。当.py执行的时候，解释器会先解释成cpython文件，进而编译执行。 IPythonIPython是基于CPython之上的一个交互式解释器，即IPython只是在交互方式上有增强，除此之外，其执行Python代码的功能和CPython是一样的。 CPython用&gt;&gt;&gt; 作为提示符，而IPython用In[no.]:作为提示符。 PyPyPyPy是另一个解释器，目标是执行速度。PyPy采用了JIT技术，对Python代码进行动态编译（不是解释），所以可以显著提高Python代码的执行速度。 绝大部份Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，导致相同的Python代码在两种解释器下执行可能有不同的结果。使用前要先了解其不同点。 JythonJython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码运行。 IronPythonIronPython和Jython类似，只不过其是运行在微软.NET平台上的Python解释器，可以直接把Python代码编译成.NET的字节码。 Reference 廖雪峰 python解释器]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web Crawler Get the User-Agent]]></title>
    <url>%2F2019%2F06%2F13%2FWeb-Crawler-Get-the-User-Agent%2F</url>
    <content type="text"><![CDATA[How to Get User-Agent for your CrawlerThere are several common ways to get the user-agent and use it to scrape the website. about:version in your browser, and check the User-Agent. Use the inspect tool within your browser. Network -&gt; refresh your page -&gt; find the current page -&gt; Headers -&gt; check the User-Agent install the fake_agent in your computer and import it for using in Python 1pip install fake_useragent When using: 12345from fake_useragent import UserAgent# import randomfake_ua=UserAgent()headers=&#123;'User-Agent':fake_ua.random&#125; Google to find some User-Agent, sush as User-Agent 汇总 Reference CSDN blog: 爬虫之UserAgent的获得方法 fake_useragent doc]]></content>
      <categories>
        <category>Web Crawler</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Error Met in First Crawler Demo]]></title>
    <url>%2F2019%2F06%2F13%2FError-Met-in-First-Crawler-Demo%2F</url>
    <content type="text"><![CDATA[When writing the crawler program, I met across several problems. This blog is to records the solution which I used in my program. Access denied when using url directlySome websites add some features to protect them from being scraped. In this case, we should add the headers. The fields in headers: User-agent: like Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36 Referer: like https://www.google.com/ (See the introduction of crawler: Web Crawler Basic) Max retries exceeded with url1requests.exceptions.SSLError: HTTPSConnectionPool(host=&apos;www.mzitu.com&apos;, port=443): Max retries exceeded with url: /184325/8 (Caused by SSLError(SSLError(&quot;bad handshake: SysCallError(60, &apos;ETIMEDOUT&apos;)&quot;))) First time to solve this question: add sleep(1) in every iteration of downloading image It improve the problem and make the program stick longer time to do crawler work, but not solve it completely. Be able to download around 300 images until failing. To improve the ability of anti-anti-spider, in the second version, I added two other functions: Randomly sleep some time when accessing the images Randomly choose the User-Agent using fake_useragent Python module. The performance is not very good. I’m not sure whether it is due to the problem of my ip. If want to have more ability of scraping, more IPs are needed in my program.(To be continued) Connection reset by peerI’m not sure what’s the reason of this problem. I add the proxies to avoid this problem. how to get the proxies. Use it in the requests.get function. Although the program become slow, it become much more robust during scraping.]]></content>
      <categories>
        <category>Web Crawler</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web Crawler Basic]]></title>
    <url>%2F2019%2F06%2F13%2FWeb-Crawler-Basic%2F</url>
    <content type="text"><![CDATA[There are several modules for accessing html through Python. Urllib and requests are two different modules in Python which can be used for crawler. For beginner, the requests is recommended. HeadersHTTP request header is the information, in the form of a text record, that a user’s browser sends to a Web serveer containing the details of what the browser wants and will accept back from server. User-AgentThe User-Agent appears in an HTTP Request Header, not an HTTP Response one. In general, the request is sent from browser to the web application. So the user-agent is filled by the browser. Different browsers will fill up this field with different values. Blog: Web Crawler Get the User-Agent RefererOptional HTTP header field that identifies the address of the webpage that linked to the resource being requested. By checking the referee, the new webpage can see where the request originated. Some websites use this to ban the crawler, and you may need to update your referer. Reference Python 爬虫基础之urllib和requests my demo of web crawler stackoverflow: HTTP request header]]></content>
      <categories>
        <category>Web Crawler</category>
      </categories>
      <tags>
        <tag>Web Crawler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Association Rules Mining]]></title>
    <url>%2F2019%2F05%2F29%2FAssociation-Rules-Mining%2F</url>
    <content type="text"><![CDATA[It also kind of Market Basket Analysis. IntroductionAn Association Rule is where X \Longrightarrow Y ($X$ implies $Y$) An item set is a set of items. If it has $k$ items, it is a $k$-itemset. Support $s$ of an itemset $X$ is the percentage of transactions in $D$ that contains $X$. Support of association rule $X \Longrightarrow Y$ is the support of the itemset $\{X,Y\}$. Confidence of the rule $X \Longrightarrow Y$ is the ratio between the transactions that contain both $X$ and $Y$ and the number of transactions that have $X$ in $D$. The problem is: Find association rules. Given: A set $I$ of items database $D$ of transactions minimum support $s$ minimum confidence $c$ Find: Association rules $X \Longrightarrow Y$ with a minimum support $s$ and minimum confidence $c$ Apriori AlgorithmThere are two pinciples of the apriori algorithm: Any subset of a frequent itemset is also frequent Any superset of an infrequent itemset is also infrequent (example see the reference 2) ImprovementsThe limitation of confidence: \operatorname{conf}(X \Longrightarrow Y)=\frac{\frac{n T \operatorname{rans}(X \cup Y)}{|D|}}{\frac{n \operatorname{Trans}(X)}{|D|}}=\frac{p(X \wedge Y)}{p(X)}=p(Y | X)If $Y$ is independent of $X$: \mathrm{p}(Y)=\mathrm{p}(Y-X). This means if you have a high probability of $p(Y)$ we have a rule with high confidence that associate independent itemset. Lift: measure indicates departure from independence of $X$ and $Y$. The lift of $X \Longrightarrow Y$ is: \operatorname{lift}(X \Longrightarrow Y)=\frac{\operatorname{conf}(X \Longrightarrow Y)}{p(Y)}=\frac{\frac{p(X \wedge Y)}{p(X)}}{p(Y)}=\frac{p(X \wedge Y)}{p(X) p(Y)}But lift is symmetric, the same for $X \Longrightarrow Y$ as $Y \Longrightarrow X$ Conviction: indicates that $X$ and $Y$ are not independent, and takes into account the direction of implication. Since the $p \rightarrow q \equiv \neg p \vee q$, and we can rewrite it as the $\neg( p \wedge \neg q)$. Therefore, the Conviction is based on this \operatorname{conv}(X \Longrightarrow Y)=\frac{p(X) p(\neg Y)}{p X \wedge \neg Y )}Conviction is a measure of the implication and has value 1 if items are unrelated. Reference Jo slide Market Basket Mining Association Rules]]></content>
      <categories>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Decision Tree]]></title>
    <url>%2F2019%2F05%2F29%2FDecision-Tree%2F</url>
    <content type="text"><![CDATA[A decision tree is like a flow chart. One merit of using decision tree is that they are interpretable. It is easy to see how they made a certain decision. Besides, the decision trees can be “hand crafted” by experts. They can also be built up using machine learning techniques. Criteria for Choosing the SplitFor classification: ID3: maximise the information gain (based on the information entropy). The information gain is kind of mutual entropy. See the blog for more details. CART: maximise the impurity decrease (based on the Gini impurity) \text {Gini}(r o o t)-\left(\operatorname{Gini}(L e f t) \frac{n_{L}}{n}+\operatorname{Gini}(\operatorname{Right}) \frac{n_{R}}{n}\right)root is the node to be split, and left and right is the impurity of the left and right branches. For regression: CART: use variance instead of gini or entropy. Choose the feature decrease the variance most. Note: When computing the information gain, impurity decrease or the variance gain, remember to multiply the weights for the left and right trees. CARTCART, the classification and regression tree. In this part, regression using the variance is going to be introduced. The procedure of building the CART: Find the best split for each feature - minimises the impurity measure Find feature that minimises impurity the most Use the best split on that feature to split the node Do the same for each of the leaf nodes （先找每个feature最好的区分点，比较所有feature的最好效果找出决定feature，然后split。不断迭代） PruningThe decision tree is easy to be overfitting. One solution is pruning. This can be done in a variety of ways, including: Reduced Error Pruning Entropy Based Merging Reduced Error PruningProcedure: Start at leaf nodes Look up branches at last decision split Replace with a leaf node predicting the majority class If validation set classification accuracy is not affected, the keep the change This is a simple and fast algorithm that can simplify over complex decision trees. Entropy Based PruningProcedure: Chose a pair of leaf nodes with the same parent What is the entropy gain from merging them If lower than a threshold, merge nodes. This doesn’t require additional data. Reference Jo Slide Decision Tree]]></content>
      <categories>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM Algorithm]]></title>
    <url>%2F2019%2F05%2F28%2FEM-Algorithm%2F</url>
    <content type="text"><![CDATA[EM algorithm is used to solve the problems which have the latent variable. Like the example mentioned in the reference 1 about the heights of boys and girls. Before explaining the EM algorith, we review the generative models. See the blog of Discriminative and Generative models and Naive Bayes. Building Probabilistic ModelsTo describe a system with uncertainty we use random variables, $X$, $Y$, $Z$, etc. The variables are described by probability mass function $\mathbb{P}(X, Y, Z)$ or if our variables are continuous, but probability densities $f_{X, Y, Z}(x, y, z)$. We build in dependencies in this joint distribution. We often think of our observations as given and the predictions as random variables. The object is to find a probability $\mathbb{P}(C | \boldsymbol{x})$. Modeling this directly is what we know as discriminative model. In generative models, we think of the problem as the joint process of generating the features and outputs together. This leads to a joint distribution $\mathbb{P}(\boldsymbol{X}, Y)$ where $X$ are your features and $Y$ is your output you are trying to predict. Write the approach like \mathbb{P}(Y | \boldsymbol{X})=\frac{\mathbb{P}(\boldsymbol{X}, Y)}{\mathbb{P}(\boldsymbol{X})}=\frac{\mathbb{P}(\boldsymbol{X}, Y)}{\sum_{Y} \mathbb{P}(\boldsymbol{X}, Y)}Latent VariableLatent variables: The random variables involed in our models, but we don’t observe and we don’t care about. If we have a latent variable $Z$ and observed variable $\boldsymbol{X}$ and we are predicting a variable $Y$ then we would marginalise over the latent variable \mathbb{P}(\boldsymbol{X}, Y)=\sum_{Z} \mathbb{P}(\boldsymbol{X}, Y, Z)Suppose we were observing the decays from two types of short-lived particle. $X$ is our observation. Assume $X$ is normally distributed with unknown means and variances: $\Theta=\left\{\mu_{1}, \sigma_{1}^{2}, \mu_{2}, \sigma_{2}^{2}\right\}$. Let $Z\in \{0,1\}$ be an indicator that it is particle 1. The probability of $X$ is given by f(X | Z, \mathbf{\Theta})=Z \mathcal{N}\left(X | \mu_{1}, \sigma_{1}^{2}\right)+(1-Z) \mathcal{N}\left(X | \mu_{2}, \sigma_{2}^{2}\right) Note: \begin{aligned} f(X | \Theta) &=\sum_{Z \in\{0,1\}} f(X, Z | \Theta)=\sum_{Z \in\{0,1\}} f(X | Z, \Theta) \mathbb{P}(Z) \\ &=\mathbb{E}_{Z}[f(X | Z, \Theta)]=p \mathcal{N}\left(X | \mu_{1}, \sigma_{1}^{2}\right)+(1-p) \mathcal{N}\left(X | \mu_{2}, \sigma_{2}^{2}\right) \end{aligned} Then the likelihood of our observed data f(\mathcal{D} | \Theta)=\prod_{X \in \mathcal{D}} f(X | \Theta)The likelihood function is a non-linear function of the parameters so cannot be immediately maximised. We have a difficulty in that our latent variable $Z$ will depend on the parameter $\Theta$, and our likelihood will depend on the latent variable. Solution: \Theta^{(t+1)}=\underset{\Theta}{\operatorname{argmax}} \sum_{Z} \mathbb{P}\left(Z | \mathcal{D}, \Theta^{(t)}\right) \log (f(\mathcal{D} | Z, \Theta))proceed iteratively by maximising the expected log-likelihood with respect to the current set of parameters. EM for Mixture of Gaussians(EM算法是求基于隐变量上的似然函数的期望。就像这样的形式$p\cdot log(f(D|Z,\Theta))+(1-p)\cdot log(f(D|Z,\Theta))$) (to be continued) The algorithm (Bishop PRML): Initialize the $\boldsymbol{\mu}_{k}$, covariance $\boldsymbol{\Sigma}_{k}$ and mixing coefficients $\pi_{k}$, and evaluate the initial value of the log likelihood. E step. Evaluate the responsibilities using the current parameter values \gamma\left(z_{n k}\right)=\frac{\pi_{k} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{j}, \boldsymbol{\Sigma}_{j}\right)}（计算每个点n对应到k隐变量的概率） M step. Re-estimate the parameters using the current responsibilities. \begin{aligned} \boldsymbol{\mu}_{k}^{\mathrm{new}} &=\frac{1}{N_{k}} \sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{x}_{n} \\ \boldsymbol{\Sigma}_{k}^{\mathrm{new}} &=\frac{1}{N_{k}} \sum_{n=1}^{N} \gamma\left(z_{n k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}^{\mathrm{new}}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}^{\mathrm{new}}\right)^{\mathrm{T}} \\ \pi_{k}^{\mathrm{new}} &=\frac{N_{k}}{N} \end{aligned}where N_{k}=\sum_{n=1}^{N} \gamma\left(z_{n k}\right)（重新计算每类隐变量k的均值$\mu$和发那个方差矩阵$\Sigma$，以及重新分配隐变量分布的概率） Evaluate the log likelihood \ln p(\mathbf{X} | \boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{\pi})=\sum_{n=1}^{N} \ln \left\{\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(\mathbf{x}_{n} | \boldsymbol{\mu}_{k}, \boldsymbol{\Sigma}_{k}\right)\right\}and check for convergence of either the parameters or the log likelihood. If the convergence criterion is not satisfied return to step 2. （计算log 似然函数，这个在最开始也计算了一次。如果没有达到要求，重新迭代再进行计算） (not fully understand…) Example of Coin TossingMLE: there is no latent variable. The event are all belong to one distribution. EM: There are latent variables. And we don’t know the $p(Z)$ where $Z$ is the latent variable. (See the example mentioned in reference 1) Reference zhihu 人人都懂EM算法 adam slide Generative Models Bishop PRML Chapter 9.2]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bayes Rule, Prior and Posterior]]></title>
    <url>%2F2019%2F05%2F27%2FBayes-Rule-Prior-and-Posterior%2F</url>
    <content type="text"><![CDATA[Bayes’ RuleThe form of bayes’ rule is \mathbb{P}\left(\mathcal{H}_{i} | \mathcal{D}\right)=\frac{\mathbb{P}\left(\mathcal{D} | \mathcal{H}_{i}\right) \mathbb{P}\left(\mathcal{H}_{i}\right)}{\mathbb{P}(\mathcal{D})} $\mathbb{P}\left(\mathcal{H}_{i} | \mathcal{D}\right)$ is the posterior probability of a hypothesis $\mathcal{H}_{i}$ (i.e. the probability of $\mathcal{H}_{i}$ after we know the data) $\mathbb{P}\left(\mathcal{D} | \mathcal{H}_{i}\right)$ is the likelihood of the data given the hypothesis. Note, that we calculated this from the forward problem $\mathbb{P}\left(\mathcal{H}_{i}\right)$ is the prior probability (i.e. the probability of $\mathcal{H}_{i}$ before we know the data) $\mathbb{P}(\mathcal{D})$ is the evidence. It is the normalising constant given by \mathbb{P}(\mathcal{D})=\sum_{i=1}^{n} \mathbb{P}\left(\mathcal{H}_{i}, \mathcal{D}\right)=\sum_{i=1}^{n} \mathbb{P}\left(\mathcal{D} | \mathcal{H}_{i}\right) \mathbb{P}\left(\mathcal{H}_{i}\right) In most of our task, what we want is the posterior probability. The bayes’ rule converts this into the forward problem. Prior and Posterior(to be continued) When the posterior is the same as the prior then the likelihood and prior distributions are said to be conjugate. The prior then is the conjugate prior. In the xxxxxx, we want to maximize the posterior probabilities(MAP), which is different with the fully bayesian inference.(2017-2018 exam paper AML) MAP and MLEMAP: maximize the posterior distribution MLE: maximum likelihood estimation In MAP, we should add a prior distribution and by adding observations and then to maximize the posterior distribution $p(w|X)$ to get the parameter. 最大似然估计是求参数$\theta$, 使似然函数$P(x_0|\theta)$最大。最大后验概率估计则是想求$\theta$使$P(x_0|\theta)P(\theta)$最大,求得的$ \theta $不单单让似然函数大，$ \theta $自己出现的先验概率(也是得到的后验概率）也得大. Reference Bishop PRML 详解最大似然估计（MLE）、最大后验概率估计（MAP) Adam slide bayes_prn comp6208]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LSTM]]></title>
    <url>%2F2019%2F05%2F27%2FLSTM%2F</url>
    <content type="text"><![CDATA[The Structure of the LSTM, which is shown in the image above. Items in the Structure Inputs $\boldsymbol{z}(t)=(\boldsymbol{x}(t), \boldsymbol{y}(t-1))$ The input is combined the input $x(t)$ and the output of last time $y(t-1)$ Network Updates ($W_*$ are the free parameters) \begin{array}{ll}{\boldsymbol{f}(t)=\boldsymbol{\sigma}\left(\mathbf{W}_{f} \boldsymbol{z}(t)\right)} & {\boldsymbol{g}(t)=\boldsymbol{\sigma}\left(\boldsymbol{W}_{g} \boldsymbol{z}(t)\right)} \\ {\boldsymbol{h}(t)=\tanh \left(\boldsymbol{W}_{h} \boldsymbol{z}(t)\right)} & {\boldsymbol{o}(t)=\boldsymbol{\sigma}\left(\boldsymbol{W}_{o} \boldsymbol{z}(t)\right)}\end{array}$\boldsymbol f(t)$ is the forget gate, $\boldsymbol g(t)$ decide the whether and what to remember from the input of this time, the $\boldsymbol h(t)$ is the input block, the $\boldsymbol o(t)$ is the output gate. Long-term memory update \boldsymbol{c}(t)=\boldsymbol{f}(t) \otimes \boldsymbol{c}(t-1)+\boldsymbol{g}(t) \otimes \boldsymbol{h}(t)It can be seen as the influence of the forget gate on the hidden state plus the memory update.(对隐含变量是否进行遗忘，加上这次的选择记忆阶段得到下一次的隐含状态的输入$c(t)$) Output $\boldsymbol{y}(t)=\boldsymbol{o}(t) \otimes \tanh (\boldsymbol{c}(t))$ The product of the output gate and the $tanh(\boldsymbol c(t))$. NoteWe can train an LSTM by unwrapping it in time. It involves four dense layers with sigmoidal(or tanh) output: those gates The LSTM is typucally very slow to train. There are a few variants of LSTMs, but all are very similar. The most popular is probably Gated Recurrent Unit (GRU). (to be continued) GRULSTM有很多变体，其中较大改动的是Gated Recurrent Unit (GRU)，这是由 Cho, et al. (2014)提出。它将忘记门和输入门合成了一个单一的 更新门。同样还混合了细胞状态和隐藏状态，和其他一些改动。最终的模型比标准的 LSTM模型要简单。效果和LSTM差不多，但是参数少了1/3，不容易过拟合。 Reference Adam lstm slide COMP6208 RNN, LSTM and GRU]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kernel Tricks]]></title>
    <url>%2F2019%2F05%2F27%2FKernel-Tricks%2F</url>
    <content type="text"><![CDATA[KernelsMany linear parametric models can be re-written into an equivalent dual representation in which the predictions are also based on linear combinations of a kernel function evaluated at the training data points. As we shall see, for models which are based on a fixed nonlinear feature space mapping $\phi(x)$, the kernel function is given by the relation k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=\boldsymbol{\phi}(\mathbf{x})^{\mathrm{T}} \boldsymbol{\phi}\left(\mathbf{x}^{\prime}\right)Dual Representation and Kernel: See an classical example of SVM from this blog. Some common forms of kernels: Linear Kernel 线性核 $\kappa \left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) =\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}$ Polynomial Kernel 多项式核 $\kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) =\left(\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}\right)^{d}$ Gaussian Kernel 高斯核 $\kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) =\exp \left(-\frac{\left|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right|^{2}}{2 \sigma^{2}}\right)$ Laplace Kernel 拉普拉斯核 $\kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) =\exp \left(-\frac{\left|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right|}{\sigma}\right)$ Sigmoid Kernel $\kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) =\tanh \left(\beta \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}+\theta\right)$ By replacing the $-\frac{1}{2\sigma^2}$ with $\lambda$ in the Gaussian Kernel, we can get the RBF kernel, which can be express as $\exp \left(-\gamma|\boldsymbol{x}-\boldsymbol{y}|^{2}\right)$. Note that the feature vector that corresponds to the Gaussian kernel has infinite dimensionality. Kernel TricksSo, what is kernel? In machine learning, a kernel is usually used to refer to the kernel trick, a method of using a linear classifier to solve a non-linear problem. The kernel trick allows us to map data into high-dimensional feature space $\boldsymbol{x} \rightarrow \phi(\boldsymbol{x})$. This can be carried out for sufficiently simple machines where parameter optimisation involve the dot product $\phi^{\mathbf{T}}(\boldsymbol{x}) \phi(\boldsymbol{y})$. The kernel function is positive semi-definite and the decomposition is always possible (see the properties in the end of this blog). In fact, we never need to explicitly calculate the extended features $\phi(\boldsymbol{x})$. This often makes working in the extended feature space very efficient as $K(\boldsymbol{x},\boldsymbol{y})$ may be quick to calculate. Constructing KernelsOne approach to build valid kernel is to choose a feature space mapping $\phi(x)$ and use it to find the corresponding kernel. Here the kernel function is defined for one-dimensional input space by k\left(x, x^{\prime}\right)=\phi(x)^{\mathrm{T}} \boldsymbol{\phi}\left(x^{\prime}\right)=\sum_{i=1}^{M} \phi_{i}(x) \phi_{i}\left(x^{\prime}\right)where $\phi(x)$ is the basis function. Another approach is to construct the kernel directly. In this way, we should have a method to test whether the kernel we build is valid. A necessary and sufficient condition for a function $k(x,x)$ to be a valid kernel is that the Gram matrix $K$, whose elements are given by $k(x,x)$, should be positive semi-definite for all possible choices of the set $x_n$. Note that a positive semi-definite matrix is not the same thing as a matrix whose elements are nonnegative. One powerful technique for constructing new kernels is to build out of simple kernels as building blocks. See the properties from the PRML book in $P_{296}$. Some questions about the Kernel Why it is important that the kernel function is positive semi-definite? Kernel functions need to be positive semi-definite so that they have sensible (nonnegative) distances. That is the margins are positive. Three properties that a positive semi-definite kernel should have: The eigenvalues of a positive semi-definite kernel function are nonnegative. A positive semi-definite kernel function can always be written as K(x,y)=\sum_i \phi_i(x)\phi_i(y)for some sets of real functions $\phi_i(x)$ The quadratic form satisfies \int f(\boldsymbol{x}) K(\boldsymbol{x}, \boldsymbol{y}) f(\boldsymbol{y}) \mathrm{d} \boldsymbol{x} \mathrm{d} \boldsymbol{y} \geq 0for any real function $f(x)$. Why kernel trick allows an SVM to seperate data points that are not linearly separable? The kernel trick projects data into the extended feature space (the space of engenfunctions of the kernel). Although an SVM finds a linear separating plane in this extended space, as the extended features are typically a non-linear function of the original features. This corresponds to finding a non-linear separating surface in the original space. Reference 周志华 《机器学习》 Bishop PRML Chapter 6]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Local Search not Respond]]></title>
    <url>%2F2019%2F05%2F27%2FHexo-Local-Search-not-Respond%2F</url>
    <content type="text"><![CDATA[When your article have some unlegal characters, the search function will not work.See the https://segmentfault.com/q/1010000013084615 discussion for more details. To debug, go to the url to see which blog rise this issue. http://localhost:4000/search.xml (通过注释并且在本地调试，发现是kernels trick这个文件有问题。) Solution应该是有非法字符，local search无法加载出来非utf-8编码的字符。通过注释排除法，找到问题根源。 Reference hexo的local search不能使用 Hexo本地搜索失效解决办法]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bias and Variance]]></title>
    <url>%2F2019%2F05%2F27%2FBias-and-Variance%2F</url>
    <content type="text"><![CDATA[Bias and VarianceA good learner classifier should have a good generalisation error. Generalisation: how well do we do on unseen data as opposed to the training data The problems in the Machine Learning can be over-constrained and under-constrained. Over-constrained: We have conflicting data to deal with. There are more equations than variables. In this case, the learner has insufficient flexibility to correctly predict all the training data. To solve this problem, we can minimise an error function, which means that we find a machine that explained the training data as best it can. Under-constrained: There are many possible solutions that are consistent with the data . Need to choose a plausible solution. Bias: the generalisation performance of the mean machine. \hat{f}_{m}(\boldsymbol{x})=\mathbb{E}_{\mathcal{D}}\left[\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)\right]which $\hat{f}_{m}(\boldsymbol{x})$ is the mean predictor(machine) value. And the bias is defined as B=\sum_{x \in \mathcal{X}} p(\boldsymbol{x})\left(\hat{f}_{m}(\boldsymbol{x})-f(\boldsymbol{x})\right)^{2}（可以看成最终训练出的分类器在训练集上进行预测，得到的所有值的平均值与每一个原target计算error） Variance: measures the expected variation from the average machine due to the fluctuations caused by the using a finite training set. V=\mathbb{E}_{\mathcal{D}}\left[\sum_{x \in \mathcal{X}} p(\boldsymbol{x})\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-\hat{f}_{m}(\boldsymbol{x})\right)^{2}\right]（训练出来的分类器，对每个训练集的输入进行预测，计算这些值的分布的方差） DecompositionThe formulas of bias and variance are already defined above. Here we are going to show the decomposition. The expected generalisation（平均泛化误差） is written as \overline{E}_{G}=\mathbb{E}_{\mathcal{D}}\left[E_{G}\left(\boldsymbol{w}_{\mathcal{D}}\right)\right]=\mathbb{E}_{\mathcal{D}}\left[\sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x})\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-f(\boldsymbol{x})\right)^{2}\right]=\sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x}) \mathbb{E}_{\mathcal{D}}\left[\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-f(\boldsymbol{x})\right)^{2}\right]=\sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x}) \mathbb{E}_{\mathcal{D}}\left[\left(\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-\hat{f}_{m}(\boldsymbol{x})\right)+\left(\hat{f}_{m}(\boldsymbol{x})-f(\boldsymbol{x})\right)\right)^{2}\right]\begin{aligned}=\sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x})( & \mathbb{E}_{\mathcal{D}}\left[\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-\hat{f}_{m}(\boldsymbol{x})\right)^{2}+\left(\hat{f}_{m}(\boldsymbol{x})-f(\boldsymbol{x})\right)^{2}\right] \\ &+\mathbb{E}_{\mathcal{D}}\left[2\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-\hat{f}_{m}(\boldsymbol{x})\right)\left(\hat{f}_{m}(\boldsymbol{x})-f(\boldsymbol{x})\right)\right] ) \end{aligned}The second term will vanish sicne the $\hat{f}_{m}(\boldsymbol{x})=\mathbb{E}_{\mathcal{D}}\left[\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)\right]$. Finally we can rewrite the generalisation formula as \begin{aligned} \mathbb{E}_{\mathcal{D}}\left[E_{G}\left(\boldsymbol{w}_{\mathcal{D}}\right)\right]=\mathbb{E}_{\mathcal{D}} &\left[\sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x})\left(\hat{f}\left(\boldsymbol{x} | \boldsymbol{w}_{\mathcal{D}}\right)-\hat{f}_{m}(\boldsymbol{x})\right)^{2}\right] \\+\sum & \sum_{\boldsymbol{x} \in \mathcal{X}} p(\boldsymbol{x})\left(\hat{f}_{m}(\boldsymbol{x})-f(\boldsymbol{x})\right)^{2}=V+B \end{aligned}Bias-Variance DilemmaThe composition mentioned above encodes how sensitive the machine is to the data. The dilemma arises because a simple machine will typically have a large bias, but small variance, while a complicated machine will have a small bias but large variance. Reference Adam slide01 COMP6208 Additional reading Bishop PRML Chapter 3.2]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Radial Basis Function, RBF network]]></title>
    <url>%2F2019%2F05%2F27%2FRadial-Basis-Function-RBF-network%2F</url>
    <content type="text"><![CDATA[Radial basis functionradial basis function is that each basis function depends only on the radial distance (typically Euclidean) from a centre $\mu_j$, so that $\phi_j(x)=h(x-\mu_j)$. $f(x)$ is expressed as a linear combination of radial basis functions, onecentred on every data point f(\mathbf{x})=\sum_{n=1}^{N} w_{n} h\left(\left\|\mathbf{x}-\mathbf{x}_{n}\right\|\right)The values of the coefficients ${w_n}$ are found by least squares. RBF Network(to be continued) Question: What are the similarities and differences between MLP, RBF networks and SVMs? All three techniques are based on the perceptron. In MLPs, the earlier layers are perceptrons, in RBFs they are radial basis functions and SVMs thet are the features corresponding to the eigenvalues of a kernel. All three can be used for regression and classification. MLPs are trained using back-propagation of errors. They have non-unique solution. Complexity depends on nunber of hidden nodes. Liable to over-fit the training data. Often use ad hoc methods such as early stopping to stop over-fitting. Can have many output nodes. RBFs typically use unsupervised learning to choose the centres for the input layer. The labelled data used to train the final layer(a perceptron). Training is fast. Can have many output nodes. Often use regulariser on the output layer. The solution found is unique. SVMs use a kernel function to perform a mapping into a very high dimensional feature space. An optimally stable perceptron is used in the feature space. This controls the capacity of the learning machine reducing the problem of over-fitting. The learning algorithm uses quadratic optimisation. The computation complexity grows as the number training patterns cubed. For very large datasets SVMs can become impractical. The solution found is unque. Reference ML学习笔记之——径向基网络 Bishop PRML chapter 6.3 question from (COMP3008 2009-2010 Q4)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM, Slack Variable and Kernel]]></title>
    <url>%2F2019%2F05%2F26%2FSVM-Slack-Variable-and-Kernel%2F</url>
    <content type="text"><![CDATA[Maximize marginThe basic idea of SVM is to maximize the margin between the support vectors and the hyperplane. The margin can be expressed as $r=\frac{\left|\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right|}{|\boldsymbol{w}|}$ For the binary classification task $y\in(-1,+1)$, the equation satisfies: y_i(w^Tx_i+b)\geqslant r\|w\|Since the $w$ and $b$ can be scaled, we can get the condition y_i(w'^Tx_i+b')\geqslant 1where $w’=\frac{w}{r}, b’=\frac{b}{r}$. In the maximizing margin process, we only consider the support vectors which locate on the margin of hyperplane. These vectors satisfy the equation, therefore, the margin can be written as $\gamma=\frac{2}{|\boldsymbol{w}|}$. Maximizing the margin is equivalent to \min _{\boldsymbol{w}, b} \frac{1}{2}\|\boldsymbol{w}\|^{2}\text { s.t. } \quad y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right) \geqslant 1, \quad i=1,2, \ldots, mLagrangianTo solve the optimization problem, apply the Lagrangian multiplier, and we get the form of the question: L(w,b,\alpha)=\frac{1}{2}\|w\|^2-\sum_i^p \alpha_i(y_i(w^Tx_i+b-1))\begin{array}{l}{\text { s.t. } \sum_{i=1}^{m} \alpha_{i} y_{i}=0} \\ {\alpha_{i} \geqslant 0, \quad i=1,2, \ldots, m}\end{array}Dual FormBefore applying the kernel functions, the dual representations are introduced. Using the lagrandian multiplier, we convert our problem from $\min _{\boldsymbol{w}, b} \frac{1}{2}|\boldsymbol{w}|^{2}$ to $\min _{\boldsymbol{w}, b}\max_{\boldsymbol{\alpha}} L(w,b,\alpha)$. And it is equivalent to \max_{\boldsymbol{\alpha}}\{ \min _{\boldsymbol{w}, b} L(w,b,\alpha)\}To minimize the inner loss function, we calculate the partial derivative of $w$ and $b$, and make them equal to $0$, an then we get the the \begin{aligned} \boldsymbol{w}=& \sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i} \\ 0 &=\sum_{i=1}^{m} \alpha_{i} y_{i} \end{aligned}Substitute the results back to the origin $L(w,b,\alpha)$ loss function, now the dual representation is \max _{\boldsymbol{\alpha}} \left ( \sum_{i=1}^{m} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j} \right)\begin{array}{l}{\text { s.t. } \sum_{i=1}^{m} \alpha_{i} y_{i}=0} \\ {\alpha_{i} \geqslant 0, \quad i=1,2, \ldots, m}\end{array}Then we can apply the kernel. Assum the kernel function which has the form like this \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left\langle\phi\left(\boldsymbol{x}_{i}\right), \phi\left(\boldsymbol{x}_{j}\right)\right\rangle=\phi\left(\boldsymbol{x}_{i}\right)^{\mathrm{T}} \phi\left(\boldsymbol{x}_{j}\right)Write the matrix form $K=\boldsymbol\phi(\boldsymbol x)\boldsymbol\phi(\boldsymbol y)$, and rewrite the dual representation as the matrix form \boldsymbol c^T \boldsymbol\alpha-\frac{1}{2}\boldsymbol\alpha^T K \boldsymbol\alphawith the constraints. The advantage of using the kernel trick: blog Kernel Function Some common form of kernels: blog Kernel Function Slack Variable对于不能完全分隔开的情况，引入松弛变量，使硬间隔(hard margin)转换成弱间隔(soft margin)。落在软间隔中的点才是我们要关注的东西，所以之后的slack variable只有在间隔内的才是不等于0的。 The form of classification constraints are replaced with \begin{array}{c}{\text { s.t. } \quad y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right) \geqslant 1-\xi_{i}} \\ {\xi_{i} \geqslant 0, i=1,2, \ldots, m}\end{array}Each slack variable is for one training data point. Data points with $ \xi_n=0$ are correctly classified and are either on the margin or on the correct side of the margin. Points for which $0&lt;\xi_{n} \leqslant 1$ lie inside the margin, but on the correct boundary, and those data points for which $\xi_n&gt;1$ lie on the wrong side of the decision boundary and are misclassified. Slack variable allow for overlapping class distributions, however this framework is still sensitive to outliers because the penalty for misclassification increase linearly with $\xi$. (错误分类的离群点，会有很大的 $\xi$ 绝对值) Therefore, the function we are going to minimize is C \sum_{n=1}^{N} \xi_{n}+\frac{1}{2}\|\mathbf{w}\|^{2}where the parameter $C&gt;0$ controls the trade-off between the salck variable penality and the margin. Because any point that is misclassified has $\xi_n&gt;1$, it follows that the $\sum_{n} \xi_{n}$ is an upper bound on the number of misclassified points. Therefore, the parameter $C$ is analogous to a regularization coefficient because it controls the trade-off between minimizing training errors and controlling the model complexity. In the limit $C \rightarrow \infty$, we will recover the earlier SVM with the hard margin. The corresponding Lagrangian is given by L(\mathbf{w}, b, \mathbf{a})=\frac{1}{2}\|\mathbf{w}\|^{2}+C \sum_{n=1}^{N} \xi_{n}-\sum_{n=1}^{N} a_{n}\left\{t_{n} y\left(\mathbf{x}_{n}\right)-1+\xi_{n}\right\}-\sum_{n=1}^{N} \mu_{n} \xi_{n}and there are the constraints(see the book) We can also convert it to the dual form and during the calculating the derivative, we get the another constraint $0 \leqslant a_{n} \leqslant C$. (since there are a lot of content which can be written down. I will omit these information. If you want to get to know more, see the Chapter 7.1.1 of PRML of Bishop) Reference 周志华 《机器学习》 Bishop PRML Chapter 7.1.1]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matrix Derivatives]]></title>
    <url>%2F2019%2F05%2F26%2FMatrix-Derivatives%2F</url>
    <content type="text"><![CDATA[Common Used in Machine LearningThere are two types of layout in the expression of matrix derivatives: denominator and numberator layout. Here we always use the denominator layout. vector to vector \frac{\partial \mathbf{A} \mathbf{x}}{\partial \mathbf{x}}=\mathbf{A}^{\top}\frac{\partial \mathbf{x}^{\top} \mathbf{A}}{\partial \mathbf{x}}= \mathbf{A} scaler to vector \frac{\partial \mathbf{x}^{\top} \mathbf{A} \mathbf{x}}{\partial \mathbf{x}}=\left(\mathbf{A}+\mathbf{A}^{\top}\right) \mathbf{x}\frac{\partial \mathbf{x}^{\mathbf{T}} \mathbf{x}}{\partial \mathbf{x}}=2 \mathbf{x}These two conclusions are very popular in the derivative calculation of Machine Learning. Reference 矩阵求导、几种重要的矩阵及常用的矩阵求导公式]]></content>
      <categories>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Linear Algebra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Naive Bayes]]></title>
    <url>%2F2019%2F05%2F26%2FNaive-Bayes%2F</url>
    <content type="text"><![CDATA[What is Generative ModelsSee the last article: discriminative models and generative models. The Naive Bayes belongs to the generative models, which model the distribution of the posterior and the process of generating the inputs. Assumption of Naive BayesThe naive bayes assumption is that all the data is conditionally independent, so if $D=(d_i|i=1,…,n)$ then p(\mathcal{D} | \boldsymbol{\theta})=\prod_{i=1}^{n} p\left(d_{i} | \boldsymbol{\theta}\right)(which also shown in the PRML P46) Example of implementing spam filterTo implement a spam filter we can treat all the words in the email as independent of each other. Given an email $\left\langle w_{1}, w_{2}, \dots, w_{n}\right\rangle$ we can compute the probability of it being spam as p(\operatorname{spam} | \mathcal{D})=\frac{\prod_{i=1}^{n} p\left(w_{i} | \operatorname{spam}\right) p(\operatorname{spam})}{p(\mathcal{D})}where the $p(spam)$ is the empirically measured frequency of spam emails. To compute the likelihood we use a database of spam and non spam emails p\left(w_{i} | s p a m\right)=\frac{\# \text { of occurances of } w_{i} \text { in spam database }}{\# \text { of words in spam database }}Here I use the assumption we mentioned above, the likelihood $p(D|spam)$ is defined by the multiplication of each $p(w_i|spam)$. (We might include pseudo counts to make this more robust). The probability of the data $D$ is p(\mathcal{D})=p(\mathcal{D} | \operatorname{spam}) p(\operatorname{spam})+p(\mathcal{D} | \neg \operatorname{spam}) p(\neg \operatorname{spam})We use exactly the same procedure to compute $p(D|\neg spam)$ as we did to compute the $p(D|spam)$. By calculating the posterior probabilities, we can get the approximate prediction on whether the email is spam or not. Reference Bishop PRML chapter 1.5.4 Shuogh blog: Discriminative and generative models AML(comp3008) 2012-2013 exam paper]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Discriminative and Generative Models]]></title>
    <url>%2F2019%2F05%2F25%2FDiscriminative-and-Generative-Models%2F</url>
    <content type="text"><![CDATA[The classification problem can be broken down into two seperate stages: The inference stage: train data to learn a model for $p(C_k|x)$ The decision stage: use these posterior probabilities to make optimal class assignments To solve the classification, there are actually three distinct approaches. Generative ModelsTo solve the inference problem, we should determine the class-conditional densities $p(x|C_k)$ for each class $C_k$ individually. Also infer the prior class probabilities $p(C_k)$. Then use Bayes’ theorem in the form p\left(\mathcal{C}_{k} | \mathbf{x}\right)=\frac{p\left(\mathbf{x} | \mathcal{C}_{k}\right) p\left(\mathcal{C}_{k}\right)}{p(\mathbf{x})}to find the posterior class probabilities $p(C_k|x)$. For the denominator, it can be calculated by p(\mathbf{x})=\sum_{k} p\left(\mathbf{x} | \mathcal{C}_{k}\right) p\left(\mathcal{C}_{k}\right). Equivalently, the joint distribution $p(x,C_k)$ can also be modelled directly and then normalize to obtain the posterior probabilities. Given the posterior probabilities, we use decision theory to determine class membership for each input $x$. This kind of method is called generative models, which model the distribution of inputs as well as the outputs. The name “generative“ is because by sampling from them it is possible to generate synthetic data points in the input space. The examples of generative models: Naive Bayes, Latent Dirichlet allocation, Gaussian Process… Discriminative ModelsSolve the inference problem of determining the posterior class probabilities $p(C_k|x)$, and then make prediction using decision theory. The methods which model the posterior probabilities $p(C_k|x)$ directly are called discriminative models. or Find a function $f(x)$, called a discriminant function, which maps each input $x$ directly onto a class label. Examples of discriminative models: kNN, perceptron, decision tree, linear regression, logistics regression, SVM, neural network… The Merits of Each MethodGenerative models are most demanding, since it involve finding the joint distribution over both $x$ and $C_k$. For many application, $X$ have high dimensionality and consequently we may need a large training set in order to be able to determine the class-conditional densities （类条件概率密度，就是后验概率，我们的目标）to reasonable accuracy.One distinctive use case of the generative models is outlier detection （离群点检测）. The margin density of data $p(x)$ can be determined using the formula menetioned above. It is usefule for detecting new data points that have low probability under the model and for which the predictions may be of low accuracy, which is know as outlier detection and novelty detection. Discriminative approaches is simpler. The second approach can obtain the posterior probabilities $p(C_k|x)$ directly from the data points. The thrid approach is much simpler, in which we use the training data to find a discriminant function $f(x)$ that maps each $x$ directly onto a class label (It combine the inference and decision stages into a single learning problem). However, in the third method, we no loner have access to posterior probabilities. Reference Bishop PRML Chapter 1.5.4]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Mining Information Theory]]></title>
    <url>%2F2019%2F05%2F25%2FData-Mining-Information-Theory%2F</url>
    <content type="text"><![CDATA[Information Theory and Feature Selection Outline: Information Entropy Mutual information for feature selection InformationInformation, also can be seen as uncertainty and surprise. $I=-log_2{p(x)}$ Since the $p(x)$ is the probability of event $x$, the value $&lt;1$. Shannon entropy: H(p)=-\sum_{x} p(x) \log _{2} p(x)( entropy = the probability of an event * information of this event ) Shannon entropy is the measure of uncertainty. (香农熵描述的是混乱程度，而且information这个概念其实也是从这个角度给出的，不确定性越大，这个事件携带的信息越多。) K-L DivergenceTwo probability distribution $f(x)$ and $g(x)$, the K-L divergence is : D(f \| g)=\sum_{x \in X} f(x) \log \frac{f(x)}{g(x)} Compare the entropy of two distribution over the same random variable Heuristically: number of additional bits encoding a random variable with distribution $f(x)$ using $g(x)$. It can be seen as the $D(f|g) =\sum_{x \in X} [-f(x)log_2 g(x)+f(x)log_2f(x)] $, the first term is to encode $f(x)$ using the the encoding method of $g(x)$.Therefore, it can be seen as the distance between two encoding function ( or distribution). When minimizing K-L against a fixed reference distribution $p$, the task is euivalent to minimizing cross entropies. It can be written as: $D(f|g) =\sum_{x \in X}f(x)log_2f(x) - \sum_{x \in X}f(x)log_2 g(x) $ The second term is what we use in the cross entropy loss function. The form of cross entropy: H(p, q)=-\sum_{x} p(x) \log _{2} q(x)Note:The K-L divergence can not be used as a measure for the distance between $f$ and $g$, since it is not symmetric, $D(f | g)$ is not equal to $D(g | y)$. Conditional EntropyThe $I$ is realized information, which is the difference between the entropy of $H(C)$ and the contional entropy $H(C|X=x)$. And the realized information is defined as: I[C ; X=x]=H(C)-H(C | X=x)Given the observation of $X$, the entropy of $C$ is decrease, which is written as $H(C | X=x)$. The realized information is not necessarily positive. If it is negative, the entropy will increase. Form of the contional entropy (from PRML): $H(Y | X)=-\sum_{x_{i}, y_{j}}^{m, n} p\left(x_{i}, y_{j}\right) \cdot \log _{2} p\left(y_{j} | x_{i}\right)$ Mutual InformationMutual information is the expected information a feature gives us about a classs: $I[C ; X]=H(C)-\sum \operatorname{Pr}(X=x) H(C | X=x)$ Note: Mutual information is always positive. Is only 0 when the X and C are statistically independent. Is symmetric in X and C Example of calculating the mutual information: Indicator X Class $C$ “Paint” “Not Paint” Art 12 45 Music 45 The entropy of C: $H(C)=57/102 \cdot log_2(57/102)+ 45/102\cdot log_2(45/102)=0.99$ $H[C|X=”paint”]=0$ ,since the “paint” can be certain that the story is about art. $H[C|X=”not paint”]=1.0$, which we can calculate from the distribution. $I[C;X]=H[C]-Pr(x=1)H[C|X=1]-Pr(X=0)H[C|X=0]$ = 0.99-12/1020-90/102 1 =0.11 Therefore, the mutual information is 0.11, which is the expected reduction in uncertainly. Note: In the decision tree, mutual information is used as information gain. The information gain is the strategy used to choose the best feature for decision. See the zhihu for more detail. And this is the way which most people use to find the informative features. Joint and Conditional Entropy$H[X, Y]=-\sum_{x, y} \operatorname{Pr}(X=x, Y=y) \log _{2} \operatorname{Pr}(X=x, Y=y)$ Kind of the joint distribution. Using this, conditional mutual information can be derivated: $I[C ; Y | X]=H[C | X]-H[C | Y, X]$ we ask how much information does Y contain about C if we “control” for X. InteractionContional mutual information $I [C ; Y | X]$ is positive: But might be smaller/larger/equal to $I[C;Y]$ If $I[C;Y|X]=0$: C and Y are conditionally independent given X; Otherwise there is an interaction between X and Y(regarding their information about C) $I[C;Y|X]&lt;I[C;Y]$: Some of the information in Y about C is redundant given X Use this to define the interaction information: $I(C;Y;X)=I(C;Y|X)-I(C;Y)$ (Actually not very familiar with this interaction) Reference CAML机器学习系列2：深入浅出ML之Entropy-Based家族 The slide from Markus: information Bishop PRML]]></content>
      <categories>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Init Modules]]></title>
    <url>%2F2019%2F05%2F14%2FPython-Init-Modules%2F</url>
    <content type="text"><![CDATA[__init__.py 文件的作用是将文件夹变为一个Python模块,Python 中的每个模块的包中，都有__init__.py 文件。 1__all__=[] The __all__ is a special variable, which defines what attribute, functions or modules can be imported into other modules. Reference Python __init__.py 作用详解 Python模块导入时全局变量”__all__“的作用 https://blog.csdn.net/chuan_day/article/details/79694319]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning Batch Normalization]]></title>
    <url>%2F2019%2F05%2F13%2FDeep-Learning-Batch-Normalization%2F</url>
    <content type="text"><![CDATA[Why we need batch normalization in neural network? It can help the neural network to converge more quickly. Make the different features into the same scale, get rid of the influence of different scale. 防止梯度爆炸和梯度消失 Reference zhihu: 神经网络中的归一化除了减少计算量，还有什么作用？ towards data science: Batch normalization in Neural Networks]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning RNN sequence model]]></title>
    <url>%2F2019%2F05%2F09%2FDeep-Learning-RNN-sequence-model%2F</url>
    <content type="text"><![CDATA[Take down the note when I came accross the bugs during doing the lab 7.3. The key words:pack padded sequence, pad packed sequence, the output of lstm model. The code is listed below: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class ImprovedRNN(nn.Module): def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim): super().__init__() self.embedding = nn.Embedding(input_dim, embedding_dim) # YOUR CODE HERE self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)# raise NotImplementedError() self.fc = nn.Linear(hidden_dim, output_dim) def forward(self, text_len): text, lengths = text_len embedded = self.embedding(text)# print(embedded.data.size()) # (sentence length, batch_size,hidden_dim)# print(lengths) # the tensor(size 64), contains the length of sizes embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths)# print(embedded.data.size()) # the packed_sequence record the series data and the tensor recording each length # YOUR CODE HERE# print(embedded[0].size()) _,(last_state,_)=self.lstm(embedded)# lstm_out_pad,length_sentence=nn.utils.rnn.pad_packed_sequence(lstm_out) print(last_state.size())# lstm_final_out=lstm_out_pad[length_sentence-1] # just use the final timestep output# lstm_out_pad [0] is the data and [1] records the length of each sentence# print("...",lstm_out.data.size(),"\n ssss",type(lstm_out.data))# print("\n haha...",lstm_out_pad)# print(lstm_out_pad[0][-1][63])# length_63=lstm_out_pad[-1][63] # Use [-1] can't get real last one # print("I'm the length of first sentence:",length_63)# print("i'm the data:",lstm_out_pad[0][length_63-1],lstm_out_pad[0][length_63 - 1][63])# print("im the length list:",lstm_out_pad[-1])# print(lstm_final_out.size()) out=self.fc(lstm_final_out)# print("emm heng?") return out# raise NotImplementedError() INPUT_DIM = len(TEXT.vocab) # 25002EMBEDDING_DIM = 50HIDDEN_DIM = 100OUTPUT_DIM = 1imodel = ImprovedRNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)# TODO: Train and evaluate the model# YOUR CODE HEREoptimizer = optim.Adam(model.parameters(), lr=0.01)torchbearer_trial = Trial(imodel, optimizer, criterion, metrics=['acc', 'loss']).to(device)torchbearer_trial.with_generators(train_generator=MyIter(train_iterator), val_generator=MyIter(valid_iterator), test_generator=MyIter(test_iterator))# torchbearer_trial.with_train_generator(MyIter(train_iterator))torchbearer_trial.run(epochs=5)torchbearer_trial.predict()]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Server set thread for Pytorch]]></title>
    <url>%2F2019%2F05%2F07%2FLinux-Server-set-thread-for-Pytorch%2F</url>
    <content type="text"><![CDATA[During the time of doing my course work for Advanced Machine Learning, I ran my deep learning scripts on the server. In the first time, I saw the %CPU of my job was always very high. (And then, the admin killed my job since it stuck other jobs…sorry, i didn’t know this at that time) To avoid the effect on other users, before runing our Pytorch scripts, we should run the following code in the beginning to set the thread. 12OMP_NUM_THREADS=1export OMP_NUM_THREADS This allow us to use only one thread in our one job.]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Rebase to keep commit log clean]]></title>
    <url>%2F2019%2F05%2F05%2FGit-Rebase-to-keep-commit-log-clean%2F</url>
    <content type="text"><![CDATA[There always be the cases that we are developing a new feature on seperate branch when we are using Git. There are many commit log like “fix type”, “correct the error” etc. When we merge the branch to master branch, we don’t want these stupid commit log appear in the commit log of master branch. To merge development branch to master branch:12git checkout mastergit merge development If we want to make our commit log clean, then you should use rebase. Rebaseexample:123456789101112131415# 开始开发一个新 feature$ git checkout -b new-feature master# 改了一些代码$ git commit -a -m "Start developing a feature"# 刚刚的修改有点问题，再改一下$ git commit -a -m "Fix something from the previous commit" # 紧急修复，直接在 master 分支上改点东西$ git checkout master# 改了一些代码$ git commit -a -m "Fix security hole" # 开始交互式地 rebase 了$ git checkout new-feature$ git rebase -i master Reference Git tips: 合并 commit 保持分支干净整洁]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Run Script even after logging out]]></title>
    <url>%2F2019%2F05%2F02%2FLinux-Run-Script-even-after-logging-out%2F</url>
    <content type="text"><![CDATA[Nohup image_haha Rerference linux后台执行命令：&amp;和nohup Nohup Command in Linux: Linux Hint]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VAE Variational Autoencoder]]></title>
    <url>%2F2019%2F05%2F01%2FVAE-Variational-Autoencoder%2F</url>
    <content type="text"><![CDATA[差分自编码器，跟普通的自编码器不同，有着他自己特殊的地方。 通过编码器学习图像的编码，得到其潜在表征向量（这里学习其作为高斯分布的参数）。 为了训练encoder和decoder，loss function由两部分组成： KL divergence来表示隐含向量与标准正态分布之间差异的loss 另外一个loss使用生成图片与原图片的均方误差来表示 Reference 部分公式推导 KL divergence Github example code]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next() in Python]]></title>
    <url>%2F2019%2F04%2F30%2FNext-in-Python%2F</url>
    <content type="text"><![CDATA[To fetch a item from generator, next() can be used: Return the next item from the iterator. If a variable is not a generator, next() can be used along with iter(). Python code snippet:12345678910111213a=[1,2,3]next(a)# output: TypeError: 'list' object is not an iteratorb=iter(a)next(b)# output: 1next(b)# output: 2next(b)# output: 3next(b)# StopIteration Example:1234567891011121314151617181920212223242526import torchimport torchvisionimport torchvision.transforms as transformsbatch_size = 256# dataset constructiontransform = transforms.Compose([ transforms.ToTensor(), # convert to tensor transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector ])train_set = torchvision.datasets.FashionMNIST( root='./data/FashionMNIST' ,train=True ,download=True ,transform=transform)train_loader = torch.utils.data.DataLoader( train_set, batch_size=batch_size)# Fetch images by next() function# Since the obj returned by DataLoader was not iterator, I also used iter()images = next(iter(train_loader))]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sklearn Split Train and Test]]></title>
    <url>%2F2019%2F04%2F30%2FSklearn-Split-Train-and-Test%2F</url>
    <content type="text"><![CDATA[There are several ways to split the data set into training data set and test data set. In this blog, I will talk about the difference between these approaches. sklearn.model_selection.train_test_splitDoc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html sklearn.model_selection.ShuffleSplitDoc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Better style for Python Programming]]></title>
    <url>%2F2019%2F04%2F29%2FBetter-style-for-Python-Programming%2F</url>
    <content type="text"><![CDATA[How to write better code with good style Python Name Conventionpython 命名规范 Type Convention Example Packages &amp; Modules lower_with_under from prefetch_generator import BackgroundGenerator Classes CapWords class Dataloader Constants CAPS_WITH_UNDER BATCH_SIZE=16 Instances lower_with_under dataset = Dataset Methods &amp; Functions lower_with_under() def visualize_tensor() Variables lower_with_under background_colour = ‘Blue’ Maintip:即使是一个打算被用作脚本的文件, 也应该是可导入的. 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行, 这是一种副作用. 主功能应该放在一个main()函数中. 12345def main(): ...if __name__ == '__main__': main() 所有的顶级代码在模块导入时都会被执行. 要小心不要去调用函数, 创建对象, 或者执行那些不应该在使用pydoc时执行的操作. Reference Python风格规范 : https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_style_rules/ 机器之心：PyTorch最佳实践，怎样才能写出一手风格优美的代码]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch CUDA experience]]></title>
    <url>%2F2019%2F04%2F29%2FPytorch-CUDA-experience%2F</url>
    <content type="text"><![CDATA[In my experience of using the lab server to train my model, I met the problem of OOM(out of memory). Here I attach some solution and thinking in the following article. Assume such scenario: The default CUDA is full and even you want to do torch.tensor([1,2,3]).cuda() you will get OOM error. You shoul trying to choose another GPU. CUDA_VISIBLE_DEVICESCode12import osos.environ[&apos;CUDA_VISIBLE_DEVICES&apos;] = &apos;2,3&apos; Add this piece of code into your script file, and when your execute your code, you will use the corrsponding GPU.(Note: This will not be useful in Jupyter Notebook.) OR 1CUDA_VISIBLE_DEVICES=2 python test.py When you execute your script file, add the CUDA_VISIBLE_DEVICES=2 in the begining. Then the script will run on the certain GPU. NoteEven you set your GPU of 2 or 3 using this way, in the output, the device will show tensor([1, 2, 3], device=&#39;cuda:0&#39;). From pytorch forum of @pjavia ‘s answer: @MrTuo This is how pytorch 0.4.1 convention works. If you say CUDA_VISIBLE_DEVICES=2, 3. Then for pytorch GPU - 2 is cuda:0 and GPU - 3 is cuda:1. Just check your code is consistent with this convention or not? And I tested on the torch 1.0.1, it seems also consistent with this answer. Torch.cuda1234torch.cuda.set_device(1)torch.tensor([1,2,3]).cuda()# output: tensor([1, 2, 3], device=&apos;cuda:1&apos;) This code of first line is useful on Jupyter Notebook. When you set certain GPU device, the following code will use this GPU. It’s kind of set the GPU environment. Torch.device12device = torch.device(&apos;cuda:3&apos;)# X = X.to(device) Set a device of certain GPU, when you are executing the code, transfer the variable into the device(it can also be CPU). Reference Set Default GPU in PyTorch Pytorch forum: CUDA_VISIBLE_DEVICE is of no use]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Commands when using Server]]></title>
    <url>%2F2019%2F04%2F28%2FLinux-Commands-when-using-Server%2F</url>
    <content type="text"><![CDATA[When I am using the lab server, there are some commands that I need to use to see the situation of server. top作用等同于任务管理器 You can see the CPU, Memory situation by using this command. nvidia-smiSee the GPU situation, the GPU memory and the some other things. ps1ps -u [username] To see the jobs of one user in this server. echoTo see the current working dir path:1echo $PWD Rerference 每天一个linux命令（44）：top命令 CUDA之nvidia-smi命令 详解]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Server virtual env]]></title>
    <url>%2F2019%2F04%2F28%2FLinux-Server-virtual-env%2F</url>
    <content type="text"><![CDATA[How to create the virtual env in the server of lab. In my group coursework for the advanced ML, I want to run the code of the first solution in this competition. The requirments wasn’t satisfied in the server, so I want to create virtual env to built such environment. This blog records the process of building envirment to run deep learning task. virtualenvIf your linux server already has the virtualenv module, you can use virtual env to create virtual environment. You can check it using pip list. In my try, I tried to install the virtualenv in the beginning. I found that the permmission is denied, since I don’t have the root access on this server supplied by teachers. I found the reason and solution in this issue. Therefore, I did another try which is the following one. Python -m venv12python3 -m venv envsource ./env/bin/activate This solution just needs you to have the Python in your system (any Linux has the Python within system). In this way, I can activate the virual environment and pip install the specific modules. 我的解决方案目标：python3.6 过程： python -m env 在python创建出来的虚拟环境中安装virtualenv 通过virtualenv创建对应python3.6版本的虚拟环境 Reference an issue on Github: Permission denied]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kaggle Competition: Humpback Whale Identification]]></title>
    <url>%2F2019%2F04%2F27%2FKaggle-Competition-Humpback-Whale-Identification%2F</url>
    <content type="text"><![CDATA[Kaggle竞赛第一名方案解读 Description of Competition目的：构建算法识别鲸鱼个体 难点： 训练样本的严重不均衡 存在接近三分之一的无标注（new whale）数据 Some new terminology: Few-shot learning: what’s few shot learning 细粒度分类: that’s why we need mask. mask-CNN,什么是mask triplet loss: ？？？ SE-resneXt154: 一个新的分类模型 伪标签：？？ Pipeline： Input of the models RGB+mask Data Augmentation: 有人提出鲸鱼尾部不对称，翻转之后是新的类别 Reference kaggle competition: Humpback Whale Identification 机器之心: Kaggle第一名竞赛方案解读]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interview-1 QuantumBlack Data Science Intern]]></title>
    <url>%2F2019%2F04%2F15%2FInterview-1-QuantumBlack-Experience%2F</url>
    <content type="text"><![CDATA[记第一次在英国公司面试 introduction第一次面试，quantum black这个公司，面试官是两个小姐姐。公司整体人很好，刚进门的时候有小哥路过还打招呼问我，后来在餐厅等候的时候还有小哥问我吃不吃巧克力，公司整体氛围相当不错。面试官也特别友善。 面试开始先有一个简单的introduction，让面试官认识你。没有准备好这个brief introduction。 面试过程表现不太好。。。感觉一是因为英语不够熟练，刚开始不太能get到小姐姐的问题，表现不好。二是后面technical方面的问题的时候，我忘了一些模型的细节，后面详细写。 case part第一部分是实际案例部分，案例问题是关于fraud detection。给定一组很大的银行的交易数据，such as 100million条，其中200条是诈骗交易，我们要进行诈骗交易的检测。 第一步让我构建feature，觉得能从之前的数据中构建出来什么feature。最开始没太理解，后来也没答好，确实不知道能构建什么feature 第二步让我建立模型来解决这个问题。我提出使用逻辑回归模型来进行预测。接着会来一连串的问题，为什么会选用逻辑回归来预测？ 我要如何训练和测试这个模型？ 关于loss function这一块，问我如何构建。 我说使用交叉熵，但是我忘了交叉熵的公式了。。。。 metric to evaluate 这个模型，我说可以使用confusion matrix。要求来画出混淆矩阵，紧张了一下没画出来，后来画出来了。问到了precision，recall和f值。结合案例又问了问题，问我应该重点关注哪个值，这里回答不好。。。 如何split training data set。这个数据严重不平衡，如何做。。。。我也不知道回答的好还是不好。。先说80 20 split，后来说可以使用cross validation来进行交叉检验。小姐姐针对这个问题提出疑问，可能有的fold没有fraud point。。。 这部分整体感觉，有点崩，也有些超时。感觉这里应该有自己的独立思考，根据相应的案例进行变通，应该是要跟面试官进行discuss的，我没做好心理准备，导致被面试官牵着走，效果也不好。模型不应该一成不变，应该根据相应的case有不同变通。 technical part这一块不是case，是要问理论的部分。这一块刚开始其实还是比较自信的，因为自我感觉理论掌握的还不错。 ROC curve之前看过ROC curve，但是这次死活也想不起来。。。难受，这个东西业界用的比较多，之前看过一次，但是这次之前忘了看，实属失误 逻辑回归这里小姐姐结合线性回归和逻辑回归来问我问题。 还好前几天看官网案例的时候看到逻辑回归用的比较多，提前准备了一下。这里主要看线性回归和逻辑回归的理解。分别问到了线性回归的方程表现形式，loss function是什么，梯度下降又是什么（这里画图来描述），如何使用梯度下降进行优化（不必要推导导数公式）。 接着问了逻辑回归和线性回归之间的联系。时间限制，我写了一个公式，小姐姐知道了我的意思就开始下一个问题了。 其他非线性分类的模型我回答了 SVM，接着让我描述SVM和他的原理。我说svm基本状态是线性分类的，要做到非线性要用kernel。接着让我描述kernel，kernel是什么。这一块花的时间比较多，我有时候没有搞明白她的意思。其实kernel我也没有办法说的很清楚，这一块是个失误。 tree - ensemble还好我提前也准备了这一块，集成学习这一块。可惜boosting部分忘记了细节，太紧张了没回答上来。 bagging，我描述了bagging的idea。小姐姐针对bagging问了我问题，这些models是一个model吗，是不是不同。 boosting，描述的没有很清楚。我没讲清楚如何训练互补的model。。。。。。给data set赋予权重，每个数据都有不同的权重（最开始没讲清楚），然后讲如何通过一个$\alpha$来变换之前之后的权重。（太紧张了，又没有提前准备，没回答好） 之后时间到了，结束。 经验教训 准备好开头的小介绍 *重要 练习好英语，case discuss部分要灵活变通，表现自己的思考 ****重要 ROC curve *重要，忘记准备了 SVM kernel *重要，学会讲这个东西 boosting *重要，忘记准备，本身会 技术的问题都问的很详细，不会问你深度学习相关的东西，就只是问你base model的问题。准备时候要有侧重点，还好我提前看过了官网上的往期project，对知道他应该更多的问传统机器学习模型部分。但是一些具体的细节需要更加深入的理解，达到能给别人讲的程度。 ****重要]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gaussian Mixed Model(GMM) and EM algorithm]]></title>
    <url>%2F2019%2F04%2F14%2FGaussian-Mixed-Model-GMM-and-EM-algorithm%2F</url>
    <content type="text"><![CDATA[IntroductionGaussian DistributionMixed Gaussian DistributionOptimization MethodReference： 知乎 高斯混合模型(GMM) 知乎 一文详解高斯混合模型原理 《统计学习方法》第九章 - EM算法及其推广——李航]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Note-2 Feature Engineering]]></title>
    <url>%2F2019%2F04%2F14%2FNote-2-Feature-Engineering%2F</url>
    <content type="text"><![CDATA[What’s Feature EngineeringIn the application of machine learning or the field of data science, to achieve better performance on prediction or classification, we should not only choose the most suitable algorithm/model, but also we should use the suitable features. Definition in wiki:1Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. In a word, the feature engineering is to manually design what the input x should be and make our models work successfully. ImportanceThe features choice are important for our task. Better features make model have more flexibility. Suitable features can use simple models Achieve better performance Sub-questions of Feature EngineeringThere are main three kinds of tasks in the feature engineering: Feature Construction Given a problem and raw data set, to construct the features using domain knowledge, is what I called feature construction. In this process, we should analyse our problem and convert it into mathematics problem, and come up with ideas what data we need and how to tackle this problem. Feature Extraction Extract the features from data set. Such as, in the document filtering or clustering task, to constuct the document/word vector, we use TF-IDF method to extract the information behind the documents. Another example in the CNN application, the kernels/filters in convolution layers are used to extract the features of images. Feature Selection Choose the most suitable features and feed them into our models. Ignore the non-relational features. These three tasks sometimes will overlap and make people confused. They are basicall the good ways for me to understand, you can choose what your think to make yourself have a better understanding. How to do?A data science pipeline is basicall followed like this: given task and understand it choose data set pre-process the data set feature engineering(extract features) model data analyse and evaluate Feature Engineering is a part of work in our data science project. There are some ways to do features engineering: Brain storm: To come up the ideas of features which maybe useful for our project Design features Choose features (… TO BE CONTINUE) Reference: image and content of ideas from this blog]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Note-1: Linear Regression and Logistic Regression]]></title>
    <url>%2F2019%2F04%2F12%2FNote-1-Linear-Regression-and-Logistic-Regression%2F</url>
    <content type="text"><![CDATA[Linear RegressionWhat’s Liear RegressionLinear Regression is a approach to modelling the relationship between a scalar response( or a dependent variable) and one or more explanatory variables. It is written as the linear formula: $f(x)=w^T x+b$ Given the features values of $n$ data points, we can train to get a linear model which can fit the data set properly. When the new data point is fed into the model, we can predict the value. We are going to find the optimal weights value: (w^*,b^*)= \underset{(w,b)}{\operatorname{argmix}}\sum^m_{i=1}(f(x_i)-y_i)^2The close form solution can be calculated through the derivative. Of course, you can also use Gradient descent to find the optimal parameters, but it’s not necessary. AdvantageThe advantages of linear regression are that it’s simple and easy to implement, and the time complexity is small. Logistic RegressionWhy Logistic RegressionThough the name of Logistic Regression includes regression, it’t not really a regression model. It’s for classification task. In this aspect, we can call Logistic Regression Analysis. Since we have Linear Regression to do the regression task to predict the value for a new data set. Actually it can be used to predict the class for a given data. We can just set the threshold, if the predicted value is above the threshold, then it is classified into class 1, on the other hand, the data is classified into class 0. However, there is a drawback when we use linear regression to do classification. We should set lots of thresholds according to different cases. And that’s why Logistic Regreesion came out. What’s Logistic RegressionSome key words in Logistic Regression: Hypothesis: Data points are Bernoulli distributed Maximum likelihood to get the cost function Gradient descent or Newton method to find the optimal solution Given the generalized linear model: $y=g^{-1}(w^Tx+b)$, the $g(\cdot)$ is called link function. The $g$ function, from unit-stop function to sigmoid function, can convert the predicted value into corresponding class. sign(x)=\begin{cases} 1,&x>0 \\ 0.5,&x=0 \cr 0,&x]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dynamic Programming in Maximum Subarray]]></title>
    <url>%2F2019%2F04%2F10%2FDynamic-Programming-in-Maximum-Subarray%2F</url>
    <content type="text"><![CDATA[Dynamic Programming in Maximum SubarrayWhen I did the problem in Leetcode, the problem of 53 is about the maximum subarray. I got in touch about the DP algorithm, which is very useful for solving this problem, converting the $O(n^3)$ to $O(n)$ complexity. There are basically three approachs for this problem, the most time consuming one is the most straightforward and simple for user to come up with. Better one is the DP algorithm, which we are going to talk about. Problem description:Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example:123Input: [-2,1,-3,4,-1,2,1,-5,4],Output: 6Explanation: [4,-1,2,1] has the largest sum = 6. Answer:1234567891011class Solution: def maxSubArray(self, nums: List[int]) -&gt; int: ''' DP algorithm ''' n = len(nums) dp = [0]*(n) dp[0] = nums[0] for i in range(1,n): dp[i] = max(dp[i-1] + nums[i], nums[i]) return max(dp) See the video for more details: Reference: Lecture from Youtube.]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>Dynamic Programming</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Computation Graph and Back Propagation]]></title>
    <url>%2F2019%2F04%2F09%2FComputation-Graph-and-Back-Propagation%2F</url>
    <content type="text"><![CDATA[Computation Graph, Back Propagation, Forward and Reversed Auto Differentiation计算图，反向传播，前向和后向自动求导。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Print in Python3]]></title>
    <url>%2F2019%2F04%2F08%2FPrint-in-Python3%2F</url>
    <content type="text"><![CDATA[Print in Python3There are two kinds of ways to output to the screen, one is sys.output.write and print. When we use print, this built-in function actually calls the stdout function. print equals stdout.write plus &quot;\n&quot;. However, when we call print, we can change the optional parameter to print multi objects into a single line. See the doc of print: print(*objects, sep=’ ‘, end=’\n’, file=sys.stdout, flush=False) To get the print without newline： 1print("your output",end=" ") My use experience:See my exercise in the binary search tree, I want to travelsal the tree node and output into a single line. 12345678910 def preOrderTraversal(self,node): ''' if you want to output the node in a single line: - change the `print` to `print(node.data,end=' ') ''' if node:# print(node.data) print(node.data,end=" ") self.preOrderTraversal(node.lchild) self.preOrderTraversal(node.rchild)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List in Python]]></title>
    <url>%2F2019%2F03%2F22%2FList-in-Python%2F</url>
    <content type="text"><![CDATA[List and For loop in PythonThis blog also include some information of the array in Numpy. Now have a list of [1,-1,1,1,1,-1], want to have another list of category corresponding to the 1 and -1. 12&gt;&gt;&gt; label=[1,-1,1,1,1,-1]&gt;&gt;&gt; cate =['a' if i==1 else 'b' for i in label] set value using the filter character in array of numpy12345&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; label=np.array([1,-1,1,1,1,-1]) # it must be the array&gt;&gt;&gt; cate=np.empty(len(label))&gt;&gt;&gt; cate[label==1]=11&gt;&gt;&gt; cate[label==-1]=-11]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode Note Two Sum]]></title>
    <url>%2F2019%2F03%2F21%2FLeetCode-Note-Two-Sum%2F</url>
    <content type="text"><![CDATA[I have tried two kinds of the algorithm. Do sum by loop and check whether the sum is equal to the target 12345for i in range(len(nums)): sumList = [nums[i]+item for item in nums[i+1:]] for sumNum in sumList: if sumNum == target: return [i, sumList.index(sumNum)+i+1] Use the index() in ListBy using this, the performance become much better. 1234for i in range(len(nums)): targetNum = target-nums[i] if targetNum in nums and nums.index(targetNum) != i: return i, nums.index(targetNum)]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ensemble Learning]]></title>
    <url>%2F2019%2F03%2F20%2FEnsemble-Learning%2F</url>
    <content type="text"><![CDATA[Ensemble LearningBaggingWhen to use bagging? 用于很强的model。 最容易overfitting的model其实不是神经网络，而是decision tree。如果你想，只要把树扎的足够深，甚至可以在training data上得到100%的准确率，但是那没有任何意义，只是overfitting而已。 Bagging就是将容易overfitting的一堆model结合起来，乱拳打死老师傅。随机森林就是在decision tree上进行bagging，将多个决策树组合起来组成随机森林。 How to get different classifier? Re-sampling your data set to form a new set Re-weighting yoru data set to form a new set Random ForestThe data set is generated by the bootstrapping, which resample the data set with replacement. In random forest, we average much less correlated trees. To implement this algorithm, not only different data subsets are used, but also we choose a subset $m \ll p$ of the features to train decision tree. Typically $m$ can range from $1$ to $\sqrt{p}$. The trees are not that good, but by averaging over huge number of trees, we can get pretty good results. Boosting用于比较弱的model。 Adaboost Can convert the weak learner to strong learner(classifier). 我自己的一个简单Adaboost demo Reference 台湾大学李宏毅的视频 课程资源: Hung-yi Lee]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Use]]></title>
    <url>%2F2019%2F03%2F20%2FLinux-Use%2F</url>
    <content type="text"><![CDATA[This blog records some basic commends about the use in Linux Server. SSHSSH is used to make connection with the remote server. Connect the server1ssh xxx@xxx.ecs.soton.ac.uk Close the connection1exit SCP1SCP is for transport between the local and remote. Transfer the entire file folder12The formmer path is the `from` location, the latter one is the destination.scp -r xxx@xxx.ecs.soton.ac.uk:/home/sa2y18/mydocuments/4_dataMining ~/Desktop/ Transfer a single fileno -r1scp xxx@xxx.ecs.soton.ac.uk:PATH LOCALPATH Use JupyterRun jupyter on the remote and open it from local port. You can follow the instruction: [http://fizzylogic.nl/2017/11/06/edit-jupyter-notebooks-over-ssh/]123jupyter notebook --no-browser --port=8080 # run on the remote machinessh -N -L 8080:localhost:8080 xxx@xxx.ecs.soton.ac.uk # run in the local machine terminal]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beyond Accuracy: Precision and Recall]]></title>
    <url>%2F2019%2F03%2F12%2FBeyond-Accuracy-Precision-and-Recall%2F</url>
    <content type="text"><![CDATA[After training a model, there are some metrics to measure the performance of the model. The accuracy is the common one. Besides, there are other things to measure the performance. Given four cases of the results:True positive (TP): actually positive, predictive is positive which is trueFalse positive (FP): actually negative, predictive is positive which is false (type 1 error)True negative (TN): actually negative, predictive is negative which is trueFalse negative (FN): actually positive, predictive is negative which is false (type 2 error) True False Positve TP FP Negative TN FN $ Precision = \frac{TP}{TP+FP} $$ Recall = \frac{TP}{TP+FN} $]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Performance Measurement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo writing]]></title>
    <url>%2F2019%2F03%2F11%2FHexo-writing%2F</url>
    <content type="text"><![CDATA[Sometimes you don’t want to see the blog in the first time as you haven’t finished it.In this case, you can use the draft. Initialize draft and publish1234$ hexo new draft "draft name"$ #before publishing, recommend to use Hexo clean$ # hexo clean$ hexo publish "draft name" Other use skills Add the link[words](link url) 站内链接 (link within blog)1&#123;% post_link blog_name link_name %&#125; link_name可以不添加，不添加情况下默认提取文章标题 Note: be careful when you add the article title, what you input through terminal may not the title of real name]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git add ignore]]></title>
    <url>%2F2019%2F03%2F11%2FGit-add-ignore%2F</url>
    <content type="text"><![CDATA[What’s gitignore for:The files which you don’t want to upload or list in your git history, such as “.DS_store” or some other data files. You can achieve this by adding the .gitignore file into your git repo. Mac .DS_storegitignore can set globally or just add a single file into your repo. You can find the doc in this link. 所有空行或者以注释符号 ＃ 开头的行都会被 git 忽略，空行可以为了可读性分隔段落，# 表明注释。 第一个 / 会匹配路径的根目录，举个栗子，”/*.html”会匹配”index.html”，而不是”d/index.html”。 通配符 匹配任意个任意字符，? 匹配一个任意字符。需要注意的是通配符不会匹配文件路径中的 /，举个栗子，”d/.html”会匹配”d/index.html”，但不会匹配”d/a/b/c/index.html”。 两个连续的星号 ** 有特殊含义： 以 / 开头表示匹配所有的文件夹，例如 /test.md 匹配所有的test.md文件。 以 / 结尾表示匹配文件夹内所有内容，例如 a/ 匹配文件夹a中所有内容。 连续星号 前后分别被 / 夹住表示匹配0或者多层文件夹，例如 a//b 匹配到 a/b 、a/x/b 、a/x/y/b 等。 前缀 ! 的模式表示如果前面匹配到被忽略，则重新添加回来。如果匹配到的父文件夹还是忽略状态，该文件还是保持忽略状态。如果路径名第一个字符为 ! ，则需要在前面增加 \ 进行转义。 Reference git doc Mac中Git忽略.DS_Store文件]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Use]]></title>
    <url>%2F2019%2F03%2F10%2FGit-Use%2F</url>
    <content type="text"><![CDATA[Quick guide book: Clone repo1$ git clone Initialize new repo Initialize and push it to a new repo in Github123456$ git init$ git remote add origin https://github.com/ShuoGH/REPONAME.git# add the repo in the github website in advance$ git push -u origin master # first to push $ git push origin master #after the first time BranchSome commend about the branches: List branches:1git branch -a Check out branchIf you want to checkout to a branch directly, just use:1git checkout origin/xxbranch To create a local branch,12345git checkout -b xx origin/xxbranch# or use git checkout -t origin/xxbranch` # it will create a branch with same name.# or use `fetch`git fetch origin xxbranch:xx # (in this way, it won't checkout to the new branch automatically) Delete branchTo delete the remote branch:1git push &lt;remote_name&gt; --delete &lt;branch_name&gt; Operation on FilesTo rm the local file and make the change into git:12git rm xx git commit -m "xxxx" Show the git tree1git log --graph --pretty=oneline --abbrev-commit]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" If you want to write a draft 1$ hexo new draft "My New Draft" More info: Writing Run server123$ hexo serveror$ hexo s More info: Server Generate static files123$ hexo generateor $ hexo g More info: Generating Deploy to remote sites123$ hexo deployor $ hexo d Before deployment, you’d better use1$ hexo clean Change the display in Home pageIf you don’t want to show the full article, it can be realised by modifying the settingauto_excerpt in the _config.yml file. More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
